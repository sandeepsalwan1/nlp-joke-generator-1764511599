/* Autogenerated by mlir-tblgen; don't manually edit */

#ifdef GEN_PASS_DECL
// Generate declarations for all passes.
#define GEN_PASS_DECL_TRITONGPUFENCEINSERTION
#define GEN_PASS_DECL_TRITONGPUPLANCTAPASS
#define GEN_PASS_DECL_TRITONNVIDIAGPUINTERLEAVETMEMPASS
#define GEN_PASS_DECL_TRITONNVIDIAGPUMMALOWERINGPASS
#define GEN_PASS_DECL_TRITONNVIDIAGPUOPTIMIZEDESCRIPTORENCODINGPASS
#define GEN_PASS_DECL_TRITONNVIDIAGPUOPTIMIZETMEMLAYOUTSPASS
#define GEN_PASS_DECL_TRITONNVIDIAGPUPROMOTELHSTOTMEMPASS
#define GEN_PASS_DECL_TRITONNVIDIAGPUREMOVETMEMTOKENSPASS
#define GEN_PASS_DECL_TRITONNVIDIAGPUTMALOWERINGPASS
#define GEN_PASS_DECL_TRITONTENSORMEMORYALLOCATIONPASS
#undef GEN_PASS_DECL
#endif // GEN_PASS_DECL

//===----------------------------------------------------------------------===//
// TritonGPUFenceInsertion
//===----------------------------------------------------------------------===//
#ifdef GEN_PASS_DECL_TRITONGPUFENCEINSERTION
struct TritonGPUFenceInsertionOptions {
  int32_t computeCapability = 90;
};
std::unique_ptr<::mlir::Pass> createTritonGPUFenceInsertion();
std::unique_ptr<::mlir::Pass> createTritonGPUFenceInsertion(TritonGPUFenceInsertionOptions options);
#undef GEN_PASS_DECL_TRITONGPUFENCEINSERTION
#endif // GEN_PASS_DECL_TRITONGPUFENCEINSERTION
#ifdef GEN_PASS_DEF_TRITONGPUFENCEINSERTION

namespace impl {
  std::unique_ptr<::mlir::Pass> createTritonGPUFenceInsertion();
} // namespace impl

namespace impl {
  std::unique_ptr<::mlir::Pass> createTritonGPUFenceInsertion(TritonGPUFenceInsertionOptions options);
} // namespace impl
namespace impl {

template <typename DerivedT>
class TritonGPUFenceInsertionBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonGPUFenceInsertionBase;

  TritonGPUFenceInsertionBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonGPUFenceInsertionBase(const TritonGPUFenceInsertionBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonGPUFenceInsertionBase& operator=(const TritonGPUFenceInsertionBase &) = delete;
  TritonGPUFenceInsertionBase(TritonGPUFenceInsertionBase &&) = delete;
  TritonGPUFenceInsertionBase& operator=(TritonGPUFenceInsertionBase &&) = delete;
  ~TritonGPUFenceInsertionBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-gpu-fence-insertion");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-gpu-fence-insertion"; }

  ::llvm::StringRef getDescription() const override { return "Insert fences across generic and async proxy"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonGPUFenceInsertion");
  }
  ::llvm::StringRef getName() const override { return "TritonGPUFenceInsertion"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Return the dialect that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::gpu::TritonGPUDialect>();
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonGPUFenceInsertionBase<DerivedT>)

  TritonGPUFenceInsertionBase(TritonGPUFenceInsertionOptions options) : TritonGPUFenceInsertionBase() {
    computeCapability = std::move(options.computeCapability);
  }
protected:
  ::mlir::Pass::Option<int32_t> computeCapability{*this, "compute-capability", ::llvm::cl::desc("device compute capability"), ::llvm::cl::init(90)};
private:

  friend std::unique_ptr<::mlir::Pass> createTritonGPUFenceInsertion() {
    return std::make_unique<DerivedT>();
  }

  friend std::unique_ptr<::mlir::Pass> createTritonGPUFenceInsertion(TritonGPUFenceInsertionOptions options) {
    return std::make_unique<DerivedT>(std::move(options));
  }
};
} // namespace impl

std::unique_ptr<::mlir::Pass> createTritonGPUFenceInsertion() {
  return impl::createTritonGPUFenceInsertion();
}

std::unique_ptr<::mlir::Pass> createTritonGPUFenceInsertion(TritonGPUFenceInsertionOptions options) {
  return impl::createTritonGPUFenceInsertion(std::move(options));
}
#undef GEN_PASS_DEF_TRITONGPUFENCEINSERTION
#endif // GEN_PASS_DEF_TRITONGPUFENCEINSERTION

//===----------------------------------------------------------------------===//
// TritonGPUPlanCTAPass
//===----------------------------------------------------------------------===//
#ifdef GEN_PASS_DECL_TRITONGPUPLANCTAPASS
#undef GEN_PASS_DECL_TRITONGPUPLANCTAPASS
#endif // GEN_PASS_DECL_TRITONGPUPLANCTAPASS
#ifdef GEN_PASS_DEF_TRITONGPUPLANCTAPASS
namespace impl {

template <typename DerivedT>
class TritonGPUPlanCTAPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonGPUPlanCTAPassBase;

  TritonGPUPlanCTAPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonGPUPlanCTAPassBase(const TritonGPUPlanCTAPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonGPUPlanCTAPassBase& operator=(const TritonGPUPlanCTAPassBase &) = delete;
  TritonGPUPlanCTAPassBase(TritonGPUPlanCTAPassBase &&) = delete;
  TritonGPUPlanCTAPassBase& operator=(TritonGPUPlanCTAPassBase &&) = delete;
  ~TritonGPUPlanCTAPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-gpu-plan-cta");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-gpu-plan-cta"; }

  ::llvm::StringRef getDescription() const override { return "plan CTA"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonGPUPlanCTAPass");
  }
  ::llvm::StringRef getName() const override { return "TritonGPUPlanCTAPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Return the dialect that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::gpu::TritonGPUDialect>();
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonGPUPlanCTAPassBase<DerivedT>)

protected:
private:
};
} // namespace impl
#undef GEN_PASS_DEF_TRITONGPUPLANCTAPASS
#endif // GEN_PASS_DEF_TRITONGPUPLANCTAPASS

//===----------------------------------------------------------------------===//
// TritonNvidiaGPUInterleaveTMemPass
//===----------------------------------------------------------------------===//
#ifdef GEN_PASS_DECL_TRITONNVIDIAGPUINTERLEAVETMEMPASS
std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUInterleaveTMemPass();
#undef GEN_PASS_DECL_TRITONNVIDIAGPUINTERLEAVETMEMPASS
#endif // GEN_PASS_DECL_TRITONNVIDIAGPUINTERLEAVETMEMPASS
#ifdef GEN_PASS_DEF_TRITONNVIDIAGPUINTERLEAVETMEMPASS

namespace impl {
  std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUInterleaveTMemPass();
} // namespace impl
namespace impl {

template <typename DerivedT>
class TritonNvidiaGPUInterleaveTMemPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonNvidiaGPUInterleaveTMemPassBase;

  TritonNvidiaGPUInterleaveTMemPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonNvidiaGPUInterleaveTMemPassBase(const TritonNvidiaGPUInterleaveTMemPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonNvidiaGPUInterleaveTMemPassBase& operator=(const TritonNvidiaGPUInterleaveTMemPassBase &) = delete;
  TritonNvidiaGPUInterleaveTMemPassBase(TritonNvidiaGPUInterleaveTMemPassBase &&) = delete;
  TritonNvidiaGPUInterleaveTMemPassBase& operator=(TritonNvidiaGPUInterleaveTMemPassBase &&) = delete;
  ~TritonNvidiaGPUInterleaveTMemPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-interleave-tmem");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-interleave-tmem"; }

  ::llvm::StringRef getDescription() const override { return "Interleave TMEM loads/stores."; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonNvidiaGPUInterleaveTMemPass");
  }
  ::llvm::StringRef getName() const override { return "TritonNvidiaGPUInterleaveTMemPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Return the dialect that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonNvidiaGPUInterleaveTMemPassBase<DerivedT>)

protected:
private:

  friend std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUInterleaveTMemPass() {
    return std::make_unique<DerivedT>();
  }
};
} // namespace impl

std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUInterleaveTMemPass() {
  return impl::createTritonNvidiaGPUInterleaveTMemPass();
}
#undef GEN_PASS_DEF_TRITONNVIDIAGPUINTERLEAVETMEMPASS
#endif // GEN_PASS_DEF_TRITONNVIDIAGPUINTERLEAVETMEMPASS

//===----------------------------------------------------------------------===//
// TritonNvidiaGPUMMALoweringPass
//===----------------------------------------------------------------------===//
#ifdef GEN_PASS_DECL_TRITONNVIDIAGPUMMALOWERINGPASS
std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUMMALoweringPass();
#undef GEN_PASS_DECL_TRITONNVIDIAGPUMMALOWERINGPASS
#endif // GEN_PASS_DECL_TRITONNVIDIAGPUMMALOWERINGPASS
#ifdef GEN_PASS_DEF_TRITONNVIDIAGPUMMALOWERINGPASS

namespace impl {
  std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUMMALoweringPass();
} // namespace impl
namespace impl {

template <typename DerivedT>
class TritonNvidiaGPUMMALoweringPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonNvidiaGPUMMALoweringPassBase;

  TritonNvidiaGPUMMALoweringPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonNvidiaGPUMMALoweringPassBase(const TritonNvidiaGPUMMALoweringPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonNvidiaGPUMMALoweringPassBase& operator=(const TritonNvidiaGPUMMALoweringPassBase &) = delete;
  TritonNvidiaGPUMMALoweringPassBase(TritonNvidiaGPUMMALoweringPassBase &&) = delete;
  TritonNvidiaGPUMMALoweringPassBase& operator=(TritonNvidiaGPUMMALoweringPassBase &&) = delete;
  ~TritonNvidiaGPUMMALoweringPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-mma-lowering");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-mma-lowering"; }

  ::llvm::StringRef getDescription() const override { return "lower mma operations if needed"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonNvidiaGPUMMALoweringPass");
  }
  ::llvm::StringRef getName() const override { return "TritonNvidiaGPUMMALoweringPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Return the dialect that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonNvidiaGPUMMALoweringPassBase<DerivedT>)

protected:
private:

  friend std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUMMALoweringPass() {
    return std::make_unique<DerivedT>();
  }
};
} // namespace impl

std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUMMALoweringPass() {
  return impl::createTritonNvidiaGPUMMALoweringPass();
}
#undef GEN_PASS_DEF_TRITONNVIDIAGPUMMALOWERINGPASS
#endif // GEN_PASS_DEF_TRITONNVIDIAGPUMMALOWERINGPASS

//===----------------------------------------------------------------------===//
// TritonNvidiaGPUOptimizeDescriptorEncodingPass
//===----------------------------------------------------------------------===//
#ifdef GEN_PASS_DECL_TRITONNVIDIAGPUOPTIMIZEDESCRIPTORENCODINGPASS
std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUOptimizeDescriptorEncodingPass();
#undef GEN_PASS_DECL_TRITONNVIDIAGPUOPTIMIZEDESCRIPTORENCODINGPASS
#endif // GEN_PASS_DECL_TRITONNVIDIAGPUOPTIMIZEDESCRIPTORENCODINGPASS
#ifdef GEN_PASS_DEF_TRITONNVIDIAGPUOPTIMIZEDESCRIPTORENCODINGPASS

namespace impl {
  std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUOptimizeDescriptorEncodingPass();
} // namespace impl
namespace impl {

template <typename DerivedT>
class TritonNvidiaGPUOptimizeDescriptorEncodingPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonNvidiaGPUOptimizeDescriptorEncodingPassBase;

  TritonNvidiaGPUOptimizeDescriptorEncodingPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonNvidiaGPUOptimizeDescriptorEncodingPassBase(const TritonNvidiaGPUOptimizeDescriptorEncodingPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonNvidiaGPUOptimizeDescriptorEncodingPassBase& operator=(const TritonNvidiaGPUOptimizeDescriptorEncodingPassBase &) = delete;
  TritonNvidiaGPUOptimizeDescriptorEncodingPassBase(TritonNvidiaGPUOptimizeDescriptorEncodingPassBase &&) = delete;
  TritonNvidiaGPUOptimizeDescriptorEncodingPassBase& operator=(TritonNvidiaGPUOptimizeDescriptorEncodingPassBase &&) = delete;
  ~TritonNvidiaGPUOptimizeDescriptorEncodingPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-optimize-descriptor-encoding");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-optimize-descriptor-encoding"; }

  ::llvm::StringRef getDescription() const override { return "Set encodings on tensor descriptor types"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonNvidiaGPUOptimizeDescriptorEncodingPass");
  }
  ::llvm::StringRef getName() const override { return "TritonNvidiaGPUOptimizeDescriptorEncodingPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Return the dialect that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::gpu::TritonGPUDialect>();
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
    registry.insert<mlir::triton::TritonDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonNvidiaGPUOptimizeDescriptorEncodingPassBase<DerivedT>)

protected:
private:

  friend std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUOptimizeDescriptorEncodingPass() {
    return std::make_unique<DerivedT>();
  }
};
} // namespace impl

std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUOptimizeDescriptorEncodingPass() {
  return impl::createTritonNvidiaGPUOptimizeDescriptorEncodingPass();
}
#undef GEN_PASS_DEF_TRITONNVIDIAGPUOPTIMIZEDESCRIPTORENCODINGPASS
#endif // GEN_PASS_DEF_TRITONNVIDIAGPUOPTIMIZEDESCRIPTORENCODINGPASS

//===----------------------------------------------------------------------===//
// TritonNvidiaGPUOptimizeTMemLayoutsPass
//===----------------------------------------------------------------------===//
#ifdef GEN_PASS_DECL_TRITONNVIDIAGPUOPTIMIZETMEMLAYOUTSPASS
std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUOptimizeTMemLayoutsPass();
#undef GEN_PASS_DECL_TRITONNVIDIAGPUOPTIMIZETMEMLAYOUTSPASS
#endif // GEN_PASS_DECL_TRITONNVIDIAGPUOPTIMIZETMEMLAYOUTSPASS
#ifdef GEN_PASS_DEF_TRITONNVIDIAGPUOPTIMIZETMEMLAYOUTSPASS

namespace impl {
  std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUOptimizeTMemLayoutsPass();
} // namespace impl
namespace impl {

template <typename DerivedT>
class TritonNvidiaGPUOptimizeTMemLayoutsPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonNvidiaGPUOptimizeTMemLayoutsPassBase;

  TritonNvidiaGPUOptimizeTMemLayoutsPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonNvidiaGPUOptimizeTMemLayoutsPassBase(const TritonNvidiaGPUOptimizeTMemLayoutsPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonNvidiaGPUOptimizeTMemLayoutsPassBase& operator=(const TritonNvidiaGPUOptimizeTMemLayoutsPassBase &) = delete;
  TritonNvidiaGPUOptimizeTMemLayoutsPassBase(TritonNvidiaGPUOptimizeTMemLayoutsPassBase &&) = delete;
  TritonNvidiaGPUOptimizeTMemLayoutsPassBase& operator=(TritonNvidiaGPUOptimizeTMemLayoutsPassBase &&) = delete;
  ~TritonNvidiaGPUOptimizeTMemLayoutsPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-optimize-tmem-layouts");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-optimize-tmem-layouts"; }

  ::llvm::StringRef getDescription() const override { return "Optimize TMEM layouts."; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonNvidiaGPUOptimizeTMemLayoutsPass");
  }
  ::llvm::StringRef getName() const override { return "TritonNvidiaGPUOptimizeTMemLayoutsPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Return the dialect that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::gpu::TritonGPUDialect>();
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
    registry.insert<mlir::triton::TritonDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonNvidiaGPUOptimizeTMemLayoutsPassBase<DerivedT>)

protected:
private:

  friend std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUOptimizeTMemLayoutsPass() {
    return std::make_unique<DerivedT>();
  }
};
} // namespace impl

std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUOptimizeTMemLayoutsPass() {
  return impl::createTritonNvidiaGPUOptimizeTMemLayoutsPass();
}
#undef GEN_PASS_DEF_TRITONNVIDIAGPUOPTIMIZETMEMLAYOUTSPASS
#endif // GEN_PASS_DEF_TRITONNVIDIAGPUOPTIMIZETMEMLAYOUTSPASS

//===----------------------------------------------------------------------===//
// TritonNvidiaGPUPromoteLHSToTMemPass
//===----------------------------------------------------------------------===//
#ifdef GEN_PASS_DECL_TRITONNVIDIAGPUPROMOTELHSTOTMEMPASS
std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUPromoteLHSToTMemPass();
#undef GEN_PASS_DECL_TRITONNVIDIAGPUPROMOTELHSTOTMEMPASS
#endif // GEN_PASS_DECL_TRITONNVIDIAGPUPROMOTELHSTOTMEMPASS
#ifdef GEN_PASS_DEF_TRITONNVIDIAGPUPROMOTELHSTOTMEMPASS

namespace impl {
  std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUPromoteLHSToTMemPass();
} // namespace impl
namespace impl {

template <typename DerivedT>
class TritonNvidiaGPUPromoteLHSToTMemPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonNvidiaGPUPromoteLHSToTMemPassBase;

  TritonNvidiaGPUPromoteLHSToTMemPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonNvidiaGPUPromoteLHSToTMemPassBase(const TritonNvidiaGPUPromoteLHSToTMemPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonNvidiaGPUPromoteLHSToTMemPassBase& operator=(const TritonNvidiaGPUPromoteLHSToTMemPassBase &) = delete;
  TritonNvidiaGPUPromoteLHSToTMemPassBase(TritonNvidiaGPUPromoteLHSToTMemPassBase &&) = delete;
  TritonNvidiaGPUPromoteLHSToTMemPassBase& operator=(TritonNvidiaGPUPromoteLHSToTMemPassBase &&) = delete;
  ~TritonNvidiaGPUPromoteLHSToTMemPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("tritongpu-promote-lhs-to-tmem");
  }
  ::llvm::StringRef getArgument() const override { return "tritongpu-promote-lhs-to-tmem"; }

  ::llvm::StringRef getDescription() const override { return "Promote LHS operand of MMAv5 op to Tensor Memory"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonNvidiaGPUPromoteLHSToTMemPass");
  }
  ::llvm::StringRef getName() const override { return "TritonNvidiaGPUPromoteLHSToTMemPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Return the dialect that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::gpu::TritonGPUDialect>();
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
    registry.insert<mlir::triton::TritonDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonNvidiaGPUPromoteLHSToTMemPassBase<DerivedT>)

protected:
private:

  friend std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUPromoteLHSToTMemPass() {
    return std::make_unique<DerivedT>();
  }
};
} // namespace impl

std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUPromoteLHSToTMemPass() {
  return impl::createTritonNvidiaGPUPromoteLHSToTMemPass();
}
#undef GEN_PASS_DEF_TRITONNVIDIAGPUPROMOTELHSTOTMEMPASS
#endif // GEN_PASS_DEF_TRITONNVIDIAGPUPROMOTELHSTOTMEMPASS

//===----------------------------------------------------------------------===//
// TritonNvidiaGPURemoveTMEMTokensPass
//===----------------------------------------------------------------------===//
#ifdef GEN_PASS_DECL_TRITONNVIDIAGPUREMOVETMEMTOKENSPASS
std::unique_ptr<::mlir::Pass> createTritonNvidiaGPURemoveTMEMTokensPass();
#undef GEN_PASS_DECL_TRITONNVIDIAGPUREMOVETMEMTOKENSPASS
#endif // GEN_PASS_DECL_TRITONNVIDIAGPUREMOVETMEMTOKENSPASS
#ifdef GEN_PASS_DEF_TRITONNVIDIAGPUREMOVETMEMTOKENSPASS

namespace impl {
  std::unique_ptr<::mlir::Pass> createTritonNvidiaGPURemoveTMEMTokensPass();
} // namespace impl
namespace impl {

template <typename DerivedT>
class TritonNvidiaGPURemoveTMEMTokensPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonNvidiaGPURemoveTMEMTokensPassBase;

  TritonNvidiaGPURemoveTMEMTokensPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonNvidiaGPURemoveTMEMTokensPassBase(const TritonNvidiaGPURemoveTMEMTokensPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonNvidiaGPURemoveTMEMTokensPassBase& operator=(const TritonNvidiaGPURemoveTMEMTokensPassBase &) = delete;
  TritonNvidiaGPURemoveTMEMTokensPassBase(TritonNvidiaGPURemoveTMEMTokensPassBase &&) = delete;
  TritonNvidiaGPURemoveTMEMTokensPassBase& operator=(TritonNvidiaGPURemoveTMEMTokensPassBase &&) = delete;
  ~TritonNvidiaGPURemoveTMEMTokensPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-gpu-remove-tmem-tokens");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-gpu-remove-tmem-tokens"; }

  ::llvm::StringRef getDescription() const override { return "remove TMEM tokens"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonNvidiaGPURemoveTMEMTokensPass");
  }
  ::llvm::StringRef getName() const override { return "TritonNvidiaGPURemoveTMEMTokensPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Return the dialect that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonNvidiaGPURemoveTMEMTokensPassBase<DerivedT>)

protected:
private:

  friend std::unique_ptr<::mlir::Pass> createTritonNvidiaGPURemoveTMEMTokensPass() {
    return std::make_unique<DerivedT>();
  }
};
} // namespace impl

std::unique_ptr<::mlir::Pass> createTritonNvidiaGPURemoveTMEMTokensPass() {
  return impl::createTritonNvidiaGPURemoveTMEMTokensPass();
}
#undef GEN_PASS_DEF_TRITONNVIDIAGPUREMOVETMEMTOKENSPASS
#endif // GEN_PASS_DEF_TRITONNVIDIAGPUREMOVETMEMTOKENSPASS

//===----------------------------------------------------------------------===//
// TritonNvidiaGPUTMALoweringPass
//===----------------------------------------------------------------------===//
#ifdef GEN_PASS_DECL_TRITONNVIDIAGPUTMALOWERINGPASS
std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUTMALoweringPass();
#undef GEN_PASS_DECL_TRITONNVIDIAGPUTMALOWERINGPASS
#endif // GEN_PASS_DECL_TRITONNVIDIAGPUTMALOWERINGPASS
#ifdef GEN_PASS_DEF_TRITONNVIDIAGPUTMALOWERINGPASS

namespace impl {
  std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUTMALoweringPass();
} // namespace impl
namespace impl {

template <typename DerivedT>
class TritonNvidiaGPUTMALoweringPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonNvidiaGPUTMALoweringPassBase;

  TritonNvidiaGPUTMALoweringPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonNvidiaGPUTMALoweringPassBase(const TritonNvidiaGPUTMALoweringPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonNvidiaGPUTMALoweringPassBase& operator=(const TritonNvidiaGPUTMALoweringPassBase &) = delete;
  TritonNvidiaGPUTMALoweringPassBase(TritonNvidiaGPUTMALoweringPassBase &&) = delete;
  TritonNvidiaGPUTMALoweringPassBase& operator=(TritonNvidiaGPUTMALoweringPassBase &&) = delete;
  ~TritonNvidiaGPUTMALoweringPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-tma-lowering");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-tma-lowering"; }

  ::llvm::StringRef getDescription() const override { return "lower to TMA load/store operations"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonNvidiaGPUTMALoweringPass");
  }
  ::llvm::StringRef getName() const override { return "TritonNvidiaGPUTMALoweringPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Return the dialect that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonNvidiaGPUTMALoweringPassBase<DerivedT>)

protected:
private:

  friend std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUTMALoweringPass() {
    return std::make_unique<DerivedT>();
  }
};
} // namespace impl

std::unique_ptr<::mlir::Pass> createTritonNvidiaGPUTMALoweringPass() {
  return impl::createTritonNvidiaGPUTMALoweringPass();
}
#undef GEN_PASS_DEF_TRITONNVIDIAGPUTMALOWERINGPASS
#endif // GEN_PASS_DEF_TRITONNVIDIAGPUTMALOWERINGPASS

//===----------------------------------------------------------------------===//
// TritonTensorMemoryAllocationPass
//===----------------------------------------------------------------------===//
#ifdef GEN_PASS_DECL_TRITONTENSORMEMORYALLOCATIONPASS
std::unique_ptr<::mlir::Pass> createTritonTensorMemoryAllocationPass();
#undef GEN_PASS_DECL_TRITONTENSORMEMORYALLOCATIONPASS
#endif // GEN_PASS_DECL_TRITONTENSORMEMORYALLOCATIONPASS
#ifdef GEN_PASS_DEF_TRITONTENSORMEMORYALLOCATIONPASS

namespace impl {
  std::unique_ptr<::mlir::Pass> createTritonTensorMemoryAllocationPass();
} // namespace impl
namespace impl {

template <typename DerivedT>
class TritonTensorMemoryAllocationPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonTensorMemoryAllocationPassBase;

  TritonTensorMemoryAllocationPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonTensorMemoryAllocationPassBase(const TritonTensorMemoryAllocationPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonTensorMemoryAllocationPassBase& operator=(const TritonTensorMemoryAllocationPassBase &) = delete;
  TritonTensorMemoryAllocationPassBase(TritonTensorMemoryAllocationPassBase &&) = delete;
  TritonTensorMemoryAllocationPassBase& operator=(TritonTensorMemoryAllocationPassBase &&) = delete;
  ~TritonTensorMemoryAllocationPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-tensor-memory-allocation");
  }
  ::llvm::StringRef getArgument() const override { return "triton-tensor-memory-allocation"; }

  ::llvm::StringRef getDescription() const override { return "Assign tensor memory allocation"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonTensorMemoryAllocationPass");
  }
  ::llvm::StringRef getName() const override { return "TritonTensorMemoryAllocationPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Return the dialect that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonTensorMemoryAllocationPassBase<DerivedT>)

protected:
private:

  friend std::unique_ptr<::mlir::Pass> createTritonTensorMemoryAllocationPass() {
    return std::make_unique<DerivedT>();
  }
};
} // namespace impl

std::unique_ptr<::mlir::Pass> createTritonTensorMemoryAllocationPass() {
  return impl::createTritonTensorMemoryAllocationPass();
}
#undef GEN_PASS_DEF_TRITONTENSORMEMORYALLOCATIONPASS
#endif // GEN_PASS_DEF_TRITONTENSORMEMORYALLOCATIONPASS
#ifdef GEN_PASS_REGISTRATION

//===----------------------------------------------------------------------===//
// TritonGPUFenceInsertion Registration
//===----------------------------------------------------------------------===//

inline void registerTritonGPUFenceInsertion() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonGPUFenceInsertion();
  });
}

// Old registration code, kept for temporary backwards compatibility.
inline void registerTritonGPUFenceInsertionPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonGPUFenceInsertion();
  });
}

//===----------------------------------------------------------------------===//
// TritonGPUPlanCTAPass Registration
//===----------------------------------------------------------------------===//

inline void registerTritonGPUPlanCTAPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return mlir::triton::nvidia_gpu::createTritonNvidiaGPUPlanCTAPass();
  });
}

// Old registration code, kept for temporary backwards compatibility.
inline void registerTritonGPUPlanCTAPassPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return mlir::triton::nvidia_gpu::createTritonNvidiaGPUPlanCTAPass();
  });
}

//===----------------------------------------------------------------------===//
// TritonNvidiaGPUInterleaveTMemPass Registration
//===----------------------------------------------------------------------===//

inline void registerTritonNvidiaGPUInterleaveTMemPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonNvidiaGPUInterleaveTMemPass();
  });
}

// Old registration code, kept for temporary backwards compatibility.
inline void registerTritonNvidiaGPUInterleaveTMemPassPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonNvidiaGPUInterleaveTMemPass();
  });
}

//===----------------------------------------------------------------------===//
// TritonNvidiaGPUMMALoweringPass Registration
//===----------------------------------------------------------------------===//

inline void registerTritonNvidiaGPUMMALoweringPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonNvidiaGPUMMALoweringPass();
  });
}

// Old registration code, kept for temporary backwards compatibility.
inline void registerTritonNvidiaGPUMMALoweringPassPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonNvidiaGPUMMALoweringPass();
  });
}

//===----------------------------------------------------------------------===//
// TritonNvidiaGPUOptimizeDescriptorEncodingPass Registration
//===----------------------------------------------------------------------===//

inline void registerTritonNvidiaGPUOptimizeDescriptorEncodingPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonNvidiaGPUOptimizeDescriptorEncodingPass();
  });
}

// Old registration code, kept for temporary backwards compatibility.
inline void registerTritonNvidiaGPUOptimizeDescriptorEncodingPassPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonNvidiaGPUOptimizeDescriptorEncodingPass();
  });
}

//===----------------------------------------------------------------------===//
// TritonNvidiaGPUOptimizeTMemLayoutsPass Registration
//===----------------------------------------------------------------------===//

inline void registerTritonNvidiaGPUOptimizeTMemLayoutsPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonNvidiaGPUOptimizeTMemLayoutsPass();
  });
}

// Old registration code, kept for temporary backwards compatibility.
inline void registerTritonNvidiaGPUOptimizeTMemLayoutsPassPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonNvidiaGPUOptimizeTMemLayoutsPass();
  });
}

//===----------------------------------------------------------------------===//
// TritonNvidiaGPUPromoteLHSToTMemPass Registration
//===----------------------------------------------------------------------===//

inline void registerTritonNvidiaGPUPromoteLHSToTMemPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonNvidiaGPUPromoteLHSToTMemPass();
  });
}

// Old registration code, kept for temporary backwards compatibility.
inline void registerTritonNvidiaGPUPromoteLHSToTMemPassPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonNvidiaGPUPromoteLHSToTMemPass();
  });
}

//===----------------------------------------------------------------------===//
// TritonNvidiaGPURemoveTMEMTokensPass Registration
//===----------------------------------------------------------------------===//

inline void registerTritonNvidiaGPURemoveTMEMTokensPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonNvidiaGPURemoveTMEMTokensPass();
  });
}

// Old registration code, kept for temporary backwards compatibility.
inline void registerTritonNvidiaGPURemoveTMEMTokensPassPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonNvidiaGPURemoveTMEMTokensPass();
  });
}

//===----------------------------------------------------------------------===//
// TritonNvidiaGPUTMALoweringPass Registration
//===----------------------------------------------------------------------===//

inline void registerTritonNvidiaGPUTMALoweringPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonNvidiaGPUTMALoweringPass();
  });
}

// Old registration code, kept for temporary backwards compatibility.
inline void registerTritonNvidiaGPUTMALoweringPassPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonNvidiaGPUTMALoweringPass();
  });
}

//===----------------------------------------------------------------------===//
// TritonTensorMemoryAllocationPass Registration
//===----------------------------------------------------------------------===//

inline void registerTritonTensorMemoryAllocationPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonTensorMemoryAllocationPass();
  });
}

// Old registration code, kept for temporary backwards compatibility.
inline void registerTritonTensorMemoryAllocationPassPass() {
  ::mlir::registerPass([]() -> std::unique_ptr<::mlir::Pass> {
    return createTritonTensorMemoryAllocationPass();
  });
}

//===----------------------------------------------------------------------===//
// TritonNvidiaGPU Registration
//===----------------------------------------------------------------------===//

inline void registerTritonNvidiaGPUPasses() {
  registerTritonGPUFenceInsertion();
  registerTritonGPUPlanCTAPass();
  registerTritonNvidiaGPUInterleaveTMemPass();
  registerTritonNvidiaGPUMMALoweringPass();
  registerTritonNvidiaGPUOptimizeDescriptorEncodingPass();
  registerTritonNvidiaGPUOptimizeTMemLayoutsPass();
  registerTritonNvidiaGPUPromoteLHSToTMemPass();
  registerTritonNvidiaGPURemoveTMEMTokensPass();
  registerTritonNvidiaGPUTMALoweringPass();
  registerTritonTensorMemoryAllocationPass();
}
#undef GEN_PASS_REGISTRATION
#endif // GEN_PASS_REGISTRATION
// Deprecated. Please use the new per-pass macros.
#ifdef GEN_PASS_CLASSES

template <typename DerivedT>
class TritonGPUFenceInsertionBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonGPUFenceInsertionBase;

  TritonGPUFenceInsertionBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonGPUFenceInsertionBase(const TritonGPUFenceInsertionBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonGPUFenceInsertionBase& operator=(const TritonGPUFenceInsertionBase &) = delete;
  TritonGPUFenceInsertionBase(TritonGPUFenceInsertionBase &&) = delete;
  TritonGPUFenceInsertionBase& operator=(TritonGPUFenceInsertionBase &&) = delete;
  ~TritonGPUFenceInsertionBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-gpu-fence-insertion");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-gpu-fence-insertion"; }

  ::llvm::StringRef getDescription() const override { return "Insert fences across generic and async proxy"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonGPUFenceInsertion");
  }
  ::llvm::StringRef getName() const override { return "TritonGPUFenceInsertion"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Register the dialects that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::gpu::TritonGPUDialect>();
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonGPUFenceInsertionBase<DerivedT>)

protected:
  ::mlir::Pass::Option<int32_t> computeCapability{*this, "compute-capability", ::llvm::cl::desc("device compute capability"), ::llvm::cl::init(90)};
};

template <typename DerivedT>
class TritonGPUPlanCTAPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonGPUPlanCTAPassBase;

  TritonGPUPlanCTAPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonGPUPlanCTAPassBase(const TritonGPUPlanCTAPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonGPUPlanCTAPassBase& operator=(const TritonGPUPlanCTAPassBase &) = delete;
  TritonGPUPlanCTAPassBase(TritonGPUPlanCTAPassBase &&) = delete;
  TritonGPUPlanCTAPassBase& operator=(TritonGPUPlanCTAPassBase &&) = delete;
  ~TritonGPUPlanCTAPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-gpu-plan-cta");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-gpu-plan-cta"; }

  ::llvm::StringRef getDescription() const override { return "plan CTA"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonGPUPlanCTAPass");
  }
  ::llvm::StringRef getName() const override { return "TritonGPUPlanCTAPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Register the dialects that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::gpu::TritonGPUDialect>();
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonGPUPlanCTAPassBase<DerivedT>)

protected:
};

template <typename DerivedT>
class TritonNvidiaGPUInterleaveTMemPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonNvidiaGPUInterleaveTMemPassBase;

  TritonNvidiaGPUInterleaveTMemPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonNvidiaGPUInterleaveTMemPassBase(const TritonNvidiaGPUInterleaveTMemPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonNvidiaGPUInterleaveTMemPassBase& operator=(const TritonNvidiaGPUInterleaveTMemPassBase &) = delete;
  TritonNvidiaGPUInterleaveTMemPassBase(TritonNvidiaGPUInterleaveTMemPassBase &&) = delete;
  TritonNvidiaGPUInterleaveTMemPassBase& operator=(TritonNvidiaGPUInterleaveTMemPassBase &&) = delete;
  ~TritonNvidiaGPUInterleaveTMemPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-interleave-tmem");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-interleave-tmem"; }

  ::llvm::StringRef getDescription() const override { return "Interleave TMEM loads/stores."; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonNvidiaGPUInterleaveTMemPass");
  }
  ::llvm::StringRef getName() const override { return "TritonNvidiaGPUInterleaveTMemPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Register the dialects that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonNvidiaGPUInterleaveTMemPassBase<DerivedT>)

protected:
};

template <typename DerivedT>
class TritonNvidiaGPUMMALoweringPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonNvidiaGPUMMALoweringPassBase;

  TritonNvidiaGPUMMALoweringPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonNvidiaGPUMMALoweringPassBase(const TritonNvidiaGPUMMALoweringPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonNvidiaGPUMMALoweringPassBase& operator=(const TritonNvidiaGPUMMALoweringPassBase &) = delete;
  TritonNvidiaGPUMMALoweringPassBase(TritonNvidiaGPUMMALoweringPassBase &&) = delete;
  TritonNvidiaGPUMMALoweringPassBase& operator=(TritonNvidiaGPUMMALoweringPassBase &&) = delete;
  ~TritonNvidiaGPUMMALoweringPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-mma-lowering");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-mma-lowering"; }

  ::llvm::StringRef getDescription() const override { return "lower mma operations if needed"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonNvidiaGPUMMALoweringPass");
  }
  ::llvm::StringRef getName() const override { return "TritonNvidiaGPUMMALoweringPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Register the dialects that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonNvidiaGPUMMALoweringPassBase<DerivedT>)

protected:
};

template <typename DerivedT>
class TritonNvidiaGPUOptimizeDescriptorEncodingPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonNvidiaGPUOptimizeDescriptorEncodingPassBase;

  TritonNvidiaGPUOptimizeDescriptorEncodingPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonNvidiaGPUOptimizeDescriptorEncodingPassBase(const TritonNvidiaGPUOptimizeDescriptorEncodingPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonNvidiaGPUOptimizeDescriptorEncodingPassBase& operator=(const TritonNvidiaGPUOptimizeDescriptorEncodingPassBase &) = delete;
  TritonNvidiaGPUOptimizeDescriptorEncodingPassBase(TritonNvidiaGPUOptimizeDescriptorEncodingPassBase &&) = delete;
  TritonNvidiaGPUOptimizeDescriptorEncodingPassBase& operator=(TritonNvidiaGPUOptimizeDescriptorEncodingPassBase &&) = delete;
  ~TritonNvidiaGPUOptimizeDescriptorEncodingPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-optimize-descriptor-encoding");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-optimize-descriptor-encoding"; }

  ::llvm::StringRef getDescription() const override { return "Set encodings on tensor descriptor types"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonNvidiaGPUOptimizeDescriptorEncodingPass");
  }
  ::llvm::StringRef getName() const override { return "TritonNvidiaGPUOptimizeDescriptorEncodingPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Register the dialects that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::gpu::TritonGPUDialect>();
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
    registry.insert<mlir::triton::TritonDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonNvidiaGPUOptimizeDescriptorEncodingPassBase<DerivedT>)

protected:
};

template <typename DerivedT>
class TritonNvidiaGPUOptimizeTMemLayoutsPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonNvidiaGPUOptimizeTMemLayoutsPassBase;

  TritonNvidiaGPUOptimizeTMemLayoutsPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonNvidiaGPUOptimizeTMemLayoutsPassBase(const TritonNvidiaGPUOptimizeTMemLayoutsPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonNvidiaGPUOptimizeTMemLayoutsPassBase& operator=(const TritonNvidiaGPUOptimizeTMemLayoutsPassBase &) = delete;
  TritonNvidiaGPUOptimizeTMemLayoutsPassBase(TritonNvidiaGPUOptimizeTMemLayoutsPassBase &&) = delete;
  TritonNvidiaGPUOptimizeTMemLayoutsPassBase& operator=(TritonNvidiaGPUOptimizeTMemLayoutsPassBase &&) = delete;
  ~TritonNvidiaGPUOptimizeTMemLayoutsPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-optimize-tmem-layouts");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-optimize-tmem-layouts"; }

  ::llvm::StringRef getDescription() const override { return "Optimize TMEM layouts."; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonNvidiaGPUOptimizeTMemLayoutsPass");
  }
  ::llvm::StringRef getName() const override { return "TritonNvidiaGPUOptimizeTMemLayoutsPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Register the dialects that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::gpu::TritonGPUDialect>();
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
    registry.insert<mlir::triton::TritonDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonNvidiaGPUOptimizeTMemLayoutsPassBase<DerivedT>)

protected:
};

template <typename DerivedT>
class TritonNvidiaGPUPromoteLHSToTMemPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonNvidiaGPUPromoteLHSToTMemPassBase;

  TritonNvidiaGPUPromoteLHSToTMemPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonNvidiaGPUPromoteLHSToTMemPassBase(const TritonNvidiaGPUPromoteLHSToTMemPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonNvidiaGPUPromoteLHSToTMemPassBase& operator=(const TritonNvidiaGPUPromoteLHSToTMemPassBase &) = delete;
  TritonNvidiaGPUPromoteLHSToTMemPassBase(TritonNvidiaGPUPromoteLHSToTMemPassBase &&) = delete;
  TritonNvidiaGPUPromoteLHSToTMemPassBase& operator=(TritonNvidiaGPUPromoteLHSToTMemPassBase &&) = delete;
  ~TritonNvidiaGPUPromoteLHSToTMemPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("tritongpu-promote-lhs-to-tmem");
  }
  ::llvm::StringRef getArgument() const override { return "tritongpu-promote-lhs-to-tmem"; }

  ::llvm::StringRef getDescription() const override { return "Promote LHS operand of MMAv5 op to Tensor Memory"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonNvidiaGPUPromoteLHSToTMemPass");
  }
  ::llvm::StringRef getName() const override { return "TritonNvidiaGPUPromoteLHSToTMemPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Register the dialects that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::gpu::TritonGPUDialect>();
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
    registry.insert<mlir::triton::TritonDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonNvidiaGPUPromoteLHSToTMemPassBase<DerivedT>)

protected:
};

template <typename DerivedT>
class TritonNvidiaGPURemoveTMEMTokensPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonNvidiaGPURemoveTMEMTokensPassBase;

  TritonNvidiaGPURemoveTMEMTokensPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonNvidiaGPURemoveTMEMTokensPassBase(const TritonNvidiaGPURemoveTMEMTokensPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonNvidiaGPURemoveTMEMTokensPassBase& operator=(const TritonNvidiaGPURemoveTMEMTokensPassBase &) = delete;
  TritonNvidiaGPURemoveTMEMTokensPassBase(TritonNvidiaGPURemoveTMEMTokensPassBase &&) = delete;
  TritonNvidiaGPURemoveTMEMTokensPassBase& operator=(TritonNvidiaGPURemoveTMEMTokensPassBase &&) = delete;
  ~TritonNvidiaGPURemoveTMEMTokensPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-gpu-remove-tmem-tokens");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-gpu-remove-tmem-tokens"; }

  ::llvm::StringRef getDescription() const override { return "remove TMEM tokens"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonNvidiaGPURemoveTMEMTokensPass");
  }
  ::llvm::StringRef getName() const override { return "TritonNvidiaGPURemoveTMEMTokensPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Register the dialects that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonNvidiaGPURemoveTMEMTokensPassBase<DerivedT>)

protected:
};

template <typename DerivedT>
class TritonNvidiaGPUTMALoweringPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonNvidiaGPUTMALoweringPassBase;

  TritonNvidiaGPUTMALoweringPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonNvidiaGPUTMALoweringPassBase(const TritonNvidiaGPUTMALoweringPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonNvidiaGPUTMALoweringPassBase& operator=(const TritonNvidiaGPUTMALoweringPassBase &) = delete;
  TritonNvidiaGPUTMALoweringPassBase(TritonNvidiaGPUTMALoweringPassBase &&) = delete;
  TritonNvidiaGPUTMALoweringPassBase& operator=(TritonNvidiaGPUTMALoweringPassBase &&) = delete;
  ~TritonNvidiaGPUTMALoweringPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-nvidia-tma-lowering");
  }
  ::llvm::StringRef getArgument() const override { return "triton-nvidia-tma-lowering"; }

  ::llvm::StringRef getDescription() const override { return "lower to TMA load/store operations"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonNvidiaGPUTMALoweringPass");
  }
  ::llvm::StringRef getName() const override { return "TritonNvidiaGPUTMALoweringPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Register the dialects that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonNvidiaGPUTMALoweringPassBase<DerivedT>)

protected:
};

template <typename DerivedT>
class TritonTensorMemoryAllocationPassBase : public ::mlir::OperationPass<mlir::ModuleOp> {
public:
  using Base = TritonTensorMemoryAllocationPassBase;

  TritonTensorMemoryAllocationPassBase() : ::mlir::OperationPass<mlir::ModuleOp>(::mlir::TypeID::get<DerivedT>()) {}
  TritonTensorMemoryAllocationPassBase(const TritonTensorMemoryAllocationPassBase &other) : ::mlir::OperationPass<mlir::ModuleOp>(other) {}
  TritonTensorMemoryAllocationPassBase& operator=(const TritonTensorMemoryAllocationPassBase &) = delete;
  TritonTensorMemoryAllocationPassBase(TritonTensorMemoryAllocationPassBase &&) = delete;
  TritonTensorMemoryAllocationPassBase& operator=(TritonTensorMemoryAllocationPassBase &&) = delete;
  ~TritonTensorMemoryAllocationPassBase() = default;

  /// Returns the command-line argument attached to this pass.
  static constexpr ::llvm::StringLiteral getArgumentName() {
    return ::llvm::StringLiteral("triton-tensor-memory-allocation");
  }
  ::llvm::StringRef getArgument() const override { return "triton-tensor-memory-allocation"; }

  ::llvm::StringRef getDescription() const override { return "Assign tensor memory allocation"; }

  /// Returns the derived pass name.
  static constexpr ::llvm::StringLiteral getPassName() {
    return ::llvm::StringLiteral("TritonTensorMemoryAllocationPass");
  }
  ::llvm::StringRef getName() const override { return "TritonTensorMemoryAllocationPass"; }

  /// Support isa/dyn_cast functionality for the derived pass class.
  static bool classof(const ::mlir::Pass *pass) {
    return pass->getTypeID() == ::mlir::TypeID::get<DerivedT>();
  }

  /// A clone method to create a copy of this pass.
  std::unique_ptr<::mlir::Pass> clonePass() const override {
    return std::make_unique<DerivedT>(*static_cast<const DerivedT *>(this));
  }

  /// Register the dialects that must be loaded in the context before this pass.
  void getDependentDialects(::mlir::DialectRegistry &registry) const override {
    registry.insert<mlir::triton::nvidia_gpu::TritonNvidiaGPUDialect>();
  }

  /// Explicitly declare the TypeID for this class. We declare an explicit private
  /// instantiation because Pass classes should only be visible by the current
  /// library.
  MLIR_DEFINE_EXPLICIT_INTERNAL_INLINE_TYPE_ID(TritonTensorMemoryAllocationPassBase<DerivedT>)

protected:
};
#undef GEN_PASS_CLASSES
#endif // GEN_PASS_CLASSES
